---
title: "Exploratory Data Analyses for PER Project"
author: "Ian Kahrilas"
date: "2/10/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(here)
library(pander)
library(ggpubr)
library(car)
library(moments)
library(patchwork)
# load in data
erp_mast_wide <- read_csv(here("data", "created_data", "erp_mast.csv"))
erp_avr_wide <- read_csv(here("data", "created_data", "erp_avr.csv"))
per_questionnaires <- read_csv(here("data", "created_data", "per_measures.csv"))
```

```{r averaging and questionnaire variable selection, include = FALSE}
lpp_elec_right <- c("B23", "B24", "B26", "B27")
lpp_elec_left <- c("A27", "A26", "A30", "A29")
epn_elec_right <- c("B25", "B26", "B24")
epn_elec_left <- c("A28", "A27", "A29")
# select variabes from questionnaire data set for analyses
measures_int <- per_questionnaires %>% 
  select(pid:valence, sex, Race, political_orientation, coffee_typical_day:typical_sleep_hours,
         anticipating:masq_aa, tmms_repair, depression)

LPP_right <- erp_mast_wide %>%
  select(all_of(lpp_elec_right), pid:prop_trials) %>% 
  filter(between(ms, 400, 1000)) %>%
  pivot_longer(., cols = all_of(lpp_elec_right), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(LPP_right = mean(mv, na.rm = TRUE),
            prop_trials = mean(prop_trials, na.rm = TRUE))

LPP_left <- erp_mast_wide %>%
  select(all_of(lpp_elec_left), pid:prop_trials) %>% 
  filter(between(ms, 400, 1000)) %>%
  pivot_longer(., cols = all_of(lpp_elec_left), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(LPP_left = mean(mv, na.rm = TRUE))

EPN_right <- erp_avr_wide %>%
  select(all_of(epn_elec_right), pid:prop_trials) %>% 
  filter(between(ms, 240, 375)) %>%
  pivot_longer(., cols = all_of(epn_elec_right), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(EPN_right = mean(mv, na.rm = TRUE))

EPN_left <- erp_avr_wide %>%
  select(all_of(epn_elec_left), pid:prop_trials) %>% 
  filter(between(ms, 240, 375)) %>%
  pivot_longer(., cols = all_of(epn_elec_left), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(EPN_left = mean(mv, na.rm = TRUE))
```

Join all the tibbles together
```{r join all tibbles together, include=FALSE}
#join all LPP tibbles plus right frontal
per_erp <- left_join(LPP_left, LPP_right, by = c("pid", "block")) %>%
  left_join(EPN_left, by = c("pid", "block")) %>%
  left_join(EPN_right, by = c("pid", "block")) %>%
  left_join(measures_int, by = c("pid", "block"))
```

Change variable classes for parsimonious exploration and analysis

```{r change variable classes}
# pid as character type
per_erp$pid <- as.character(per_erp$pid)
# block as factor
per_erp$block <- as.factor(per_erp$block)
per_erp <- per_erp %>% 
  select(pid, block, prop_trials, everything())
```
## Questionnaire Descriptive Statisitcs

```{r descriptive stats on variables of interest}
per_erp %>% 
  ungroup() %>% 
  summarize("PA Mean" = mean(pos_affectivity, na.rm = TRUE),
            "PA SD" = sd(pos_affectivity, na.rm = TRUE),
            "NA Mean" = mean(neg_affectivity, na.rm = TRUE),
            "NA SD" = sd(neg_affectivity, na.rm = TRUE),
            "StM Mean" = mean(savoring_moment, na.rm = TRUE),
            "StM SD" = sd(savoring_moment, na.rm = TRUE)) %>% 
  pander(split.tables = 200, caption = "PA = Positive Affectivity, NA = Negative Affectivity, StM = Savoring the Moment")
```

## EEG Descriptive Statistics by Block

```{r descriptive statistics for LPP}
per_erp %>% 
  group_by(block) %>% 
  summarize("LPP Right Mean" = mean(LPP_right, na.rm = TRUE),
            "LPP Right SD" = sd(LPP_right, na.rm = TRUE),
            "LPP Left Mean" = mean(LPP_left, na.rm = TRUE),
            "LPP Left SD" = sd(LPP_left, na.rm = TRUE),
            "EPN Right Mean" = mean(EPN_right, na.rm = TRUE),
            "EPN Right SD" = sd(EPN_right, na.rm = TRUE),
            "EPN Left Mean" = mean(EPN_left, na.rm = TRUE),
            "EPN Left SD" = sd(EPN_left, na.rm = TRUE),
            "Valence Mean" = mean(valence, na.rm = TRUE),
            "Valence SD" = sd(valence, na.rm = TRUE),
            "Arousal Mean" = mean(arousal, na.rm = TRUE),
            "Arousal SD" = sd(arousal, na.rm = TRUE), 
            "Difficulty Mean" = mean(difficulty, na.rm = TRUE),
            "Difficulty SD" = sd(difficulty, na.rm = TRUE))
```

# Normality Tests

## Positive Affectivity

```{r PA histogram}
per_erp %>% 
  group_by(pid) %>% 
  summarize(pos_affectivity = mean(pos_affectivity, na.rm = TRUE)) %>% 
  ggplot(., (aes(pos_affectivity))) +
    geom_histogram(bins = 15) +
    ggtitle("PA Histogram")
```

```{r PA QQplot}
per_erp %>% 
  group_by(pid) %>% 
  summarize(pos_affectivity = mean(pos_affectivity, na.rm = TRUE)) %>% 
  ggplot(., aes(sample = pos_affectivity)) + 
  stat_qq() +
  stat_qq_line() +
  ggtitle("PA QQPlot")
```

It would appear that there is a slight negative skew to the data, though it does not deviate from a gaussian distribution substantially. Let's confirm with a shapiro-wilk test for normality

```{r shapiro-wilk test for positive affectivity, echo = FALSE}
pid_pa <- per_erp %>% 
  group_by(pid) %>% 
  summarize(pos_affectivity = mean(pos_affectivity, na.rm = TRUE))
shapiro.test(pid_pa$pos_affectivity) %>% 
  pander()
```

It is not significant, suggesting that the distribution of PA does not significantly deviate from the normal distribution.

## Negative Affectivity

```{r negative affectivity histogram}
per_erp %>% 
  group_by(pid) %>% 
  summarize(neg_affectivity = mean(neg_affectivity, na.rm = TRUE)) %>% 
  ggplot(., (aes(neg_affectivity))) +
    geom_histogram(bins = 15) +
    ggtitle("NA Histogram")
```

```{r negative affectivity qqplot}
per_erp %>% 
  group_by(pid) %>% 
  summarize(neg_affectivity = mean(neg_affectivity, na.rm = TRUE)) %>% 
  ggplot(., aes(sample = neg_affectivity)) + 
  stat_qq() +
  stat_qq_line() +
  ggtitle("NA QQPlot")
```

```{r shapiro-wilk test for NA}
pid_na <- per_erp %>% 
  group_by(pid) %>% 
  summarize(neg_affectivity = mean(neg_affectivity, na.rm = TRUE))
shapiro.test(pid_na$neg_affectivity) %>% 
  pander()
```

NA does not significantly deviate from the normal distribution.

## Savoring the Moment

```{r StM histogram}
per_erp %>% 
  group_by(pid) %>% 
  summarize(savoring_moment = mean(savoring_moment, na.rm = TRUE)) %>% 
  ggplot(., (aes(savoring_moment))) +
    geom_histogram(bins = 14) +
    ggtitle("Savoring the Moment Histogram")
```

```{r StM qqplot}
per_erp %>% 
  group_by(pid) %>% 
  summarize(savoring_moment = mean(savoring_moment, na.rm = TRUE)) %>% 
  ggplot(., aes(sample = savoring_moment)) + 
  stat_qq() +
  stat_qq_line() +
  ggtitle("Savoring the Moment QQPlot")
```
```{r shapiro-wilk test for StM}
pid_StM <- per_erp %>% 
  group_by(pid) %>% 
  summarize(savoring_moment = mean(savoring_moment, na.rm = TRUE))
shapiro.test(pid_StM$savoring_moment) %>% 
  pander()
```

## LPP

### Histograms and QQplots for each block
```{r histograms and qqplots for LPP and EPN for each block, warning = FALSE, message = FALSE}
eeg_by_pid <- per_erp %>% 
  group_by(pid, block) %>% 
  summarize(LPP_right = mean(LPP_right, na.rm = TRUE),
            LPP_left = mean(LPP_left, na.rm = TRUE),
            EPN_right = mean(EPN_right, na.rm = TRUE),
            EPN_left = mean(EPN_left, na.rm = TRUE))

hist_qq_fun <- function(block, component) {
histogram <- eeg_by_pid %>% 
  filter(block == block) %>% 
  select(.data[[component]]) %>% 
  gghistogram(., x = component)
qq <- eeg_by_pid %>% 
  filter(block == block) %>% 
  select(.data[[component]]) %>% 
  ggqqplot(., component)
(histogram | qq) +
  plot_annotation(title = paste(block, component))
}


blocks <- unique(as.character(eeg_by_pid$block))
components <- names(eeg_by_pid)[3:6]

map(components, ~map(blocks, ~hist_qq_fun(block = .x, component = .y), .y = .x))
# this is not correct, but progress
```

```{r shapiro-wilk tests for normality}
shapiro_LPP <- function(condition, title) {
result <- shapiro.test(pull(filter(LPP_by_pid, block == condition))) %>% 
  pander(caption = title)
  }
```

```{r negative decrease}
shapiro_LPP("Neg_Dec", "Negative Decrease")
```

```{r negative increase}
shapiro_LPP("Neg_Inc", "Negative Increase")
```

```{r negative watch}
shapiro_LPP("Neg_Watch", "Negative Watch")
```

```{r neutral watch}
shapiro_LPP("Neu_Watch", "Neutral Watch")
```

```{r positive decrease}
shapiro_LPP("Pos_Dec", "Positive Decrease")
```
```{r positive increase}
shapiro_LPP("Pos_Inc", "Positive Increase")
```

```{r positive watch}
shapiro_LPP("Pos_Watch", "Positive Watch")
```

Several of the conditions have LPPs that are non-normally distributed with some outliers. Let's inspect these extreme cases.

```{r examine extreme cases, warning=FALSE,message=FALSE}
extreme_cases <- function(condition, name) {
(cases <- LPP_by_pid %>% 
  filter(block == condition,
         LPP > 17))
cases %>% 
  select(pid) %>% 
  pull()
}
# this outputs participants that have LPP amplitudes greater than 17, which denote the extreme cases we observed in the histograms and qqplots.
map2(conditions, cond_names, ~ extreme_cases(.x, .y)) %>% 
  unlist() %>% 
  unique()
```

Our extreme cases are 206201843 and 206201840. Reviewing our EEG trial notes indicates that these two particpants were moving throughout the PER task. Review of their raw data in BESA indicated abnormalities with participant 206201843. However, participant 206201840's data appeared valid. Therefore, participant 206201843 will be removed, but participant 206201840 will remain. Visualizations and normality tests will be re-run without 206201843.

```{r remove noisy participants, warning=FALSE, message=FALSE}
LPP_pid_rem <- LPP_by_pid %>% 
  filter(!(pid %in% c(206201843)))
# re-run normality tests to see what's going on
LPP_hist_qq <- function(cond, title) {
LPP_pid_rem %>% 
  filter(block == cond) %>% 
  gghistogram(., "LPP", title = title) %>% 
    print()
LPP_pid_rem %>% 
  filter(block == cond) %>% 
  ggqqplot(., "LPP", title = title)
invisible(cond)
}

conditions <- unique(LPP_by_pid$block)
cond_names <- c(paste("Negative", c("Decrease", "Increase", "Watch")), "Neutral Watch", paste("Positive", c("Decrease", "Increase", "Watch")))

map2(conditions, cond_names, ~ LPP_hist_qq(cond = .x, title = .y))
```

```{r shapiro wilk tests with filtered data}
shapiro_LPP <- function(condition, title) {
shapiro.test(pull(filter(LPP_pid_rem, block == condition))) %>%
  pander(caption = title)
}

shapiro_LPP("Neg_Dec", "Negative Decrease")
```

```{r}
shapiro_LPP("Neg_Inc", "Negative Increase")
```

```{r}
shapiro_LPP("Neg_Watch", "Negative Watch")
```

```{r}
shapiro_LPP("Neu_Watch", "Neutral Watch")
```

```{r}
shapiro_LPP("Pos_Dec", "Positive Decrease")
```

```{r}
shapiro_LPP("Pos_Inc", "Positive Increase")
```

```{r}
shapiro_LPP("Pos_Watch", "Positive Watch")
```

Some are still significantly different from the normal distribution, even with the removal of the extreme case. This indicates that a non-parametric technique should be utilized for tests that assume normal data. 

```{r manipulate the dataset to facilitate bivariate analyses}
# construct a second data frame without the outlier cases
per_erp_int <- per_erp %>% 
  select(pid, block, LPP, arousal:valence, anticipating:erq_suppression) %>% 
    filter(!(pid %in% c(206201843)))
```

# Bivariate Relationships

## LPP and block condition

```{r visualize LPP by block}
ggplot(per_erp_int, aes(block, LPP)) +
  geom_boxplot() +
  ggtitle("Box and whisker plots for each block")
```

```{r ANOVAs}
per_erp_int$block <- as.factor(per_erp_int$block)
per_erp_int$block <- relevel(per_erp_int$block, "Neu_Watch")
per_erp_int_watch <- per_erp_int %>% 
  filter(block %in% c("Neu_Watch", "Pos_Watch", "Neg_Watch"))
mod_block <- lmerTest::lmer(LPP ~ block + (1|pid), data = per_erp_int)
print(psycho::analyze(mod_block))
mod_block_arousal <- lmerTest::lmer(arousal ~ block + (1|pid), data = per_erp_int)
psycho::analyze(mod_block_arousal)
mod_block_valence <- lmerTest::lmer(valence ~ block + (1|pid), data = per_erp_int)
psycho::analyze(mod_block_valence)
```


## LPP and Positive Affectivity

Derive contrasts between neutral watch and positive watch conditions and observe relationship between this contrast and positive affectivity, which is in line with the study hypothesis that the LPP contrast between the neutral watch and positive watch conditions will be moderated by positive affectivity

```{r pos affectivity contrasts}
pos_watch_contrast <- per_erp_int %>% 
  filter(block == "Neu_Watch") %>%
  rename("LPP_neu_watch" = LPP) %>% 
  select(-block)

tmp <- per_erp_int %>% 
  filter(block == "Pos_Watch") %>% 
  rename("LPP_pos_watch" = LPP) %>% 
  select(pid, LPP_pos_watch)

pos_watch_contrast <- full_join(pos_watch_contrast, tmp, by = "pid") %>% 
  mutate(contrast = LPP_pos_watch - LPP_neu_watch)

ggplot(pos_watch_contrast, aes(pos_affectivity, contrast)) +
  geom_point() +
  ggtitle("Positive affectivity and contrast between \nNeutral Watch and Positive Watch")
```

There doesn't appear to be any relationship between the two. We can derive a Pearson Product Moment correlation coefficient between contrasts and positive affectivity to validate this.

```{r}
cor.test(pos_watch_contrast$contrast, pos_watch_contrast$pos_affectivity) %>% pander()
```

## LPP and savoring the  moment

Derive contrasts between positive watch and positive increase conditions and observe relationship between this contrast and savoring the moment, which is in line with the study hypothesis that the LPP contrast between the positive watch and positive increase conditions will be moderated by savoring the moment.

```{r savoring moment contrasts}
pos_inc_contrast <- per_erp_int %>% 
  filter(block == "Pos_Watch") %>%
  rename("LPP_pos_watch" = LPP) %>% 
  select(-block)

tmp <- per_erp_int %>% 
  filter(block == "Pos_Inc") %>% 
  rename("LPP_pos_inc" = LPP) %>% 
  select(pid, LPP_pos_inc)

pos_inc_contrast <- full_join(pos_inc_contrast, tmp, by = "pid") %>% 
  mutate(contrast = LPP_pos_inc - LPP_pos_watch)

ggplot(pos_inc_contrast, aes(savoring_moment, contrast)) +
  geom_jitter() +
  ggtitle("Momentary savoring and contrast between \nPositive Watch and Positive Increase")
```

Again, there does not appear to be a relationship between the two variables. Let's derive Pearson Product Moment correlation coefficient between the contrast and savoring the moment to confirm.

```{r}
cor.test(pos_inc_contrast$contrast, pos_inc_contrast$savoring_moment) %>% pander()
```

## LPP and arousal ratings

Scatterplot between LPP and arousal ratings

```{r arousal ratings and LPP}
ggplot(per_erp_int, aes(arousal, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) +
  ggtitle("Arousal ratings and LPP")
```

There appears to be a positive linear relationship between the two. Let's test a linear model using MLM to account for the clustering between participants.

```{r}
mod_arousal <- lmerTest::lmer(LPP ~ arousal + (1|pid), data = per_erp_int)

summary(mod_arousal)
```

Results indicate a significant linear relationship between arousal and LPP.

## LPP and valence ratings

Scatterplot between LPP and valence ratings

```{r valence ratings and LPP, warning=FALSE, message=FALSE}
ggplot(per_erp_int, aes(valence, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) + 
  ggtitle("Valence ratings and LPP")
```

At first glance, there does not appear to be a relationship. However, it is hypothesized that more negatively- and positively-valenced images may positively correlate with LPP. Let's test this by fitting a polynomial regression line through the scatterplot.

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(valence, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) + 
  stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  ggtitle("Valence ratings and LPP")
```

Now, conduct a polynomial regression using MLM.

```{r}
mod_valence <- lmerTest::lmer(LPP ~ poly(valence, 2) + (1|pid), data = per_erp_int)

summary(mod_valence)
```

Results indicate that there is a curvilinear relationship between LPP and arousal.

## LPP and difficulty ratings

Scatterplot between LPP and dificulty ratings.

```{r difficulty ratings and LPP, warning=FALSE, message=FALSE}
ggplot(per_erp_int, aes(difficulty, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) + 
  ggtitle("Difficulty ratings and LPP")
```

There may be a slight linear relationship, though it is weak. Let's try fitting a linear model to test this.

```{r, warning=FALSE, message=FALSE}
mod_difficulty <- lmerTest::lmer(LPP ~ difficulty + (1|pid), data = per_erp_int)

summary(mod_difficulty)
```

There does appear to be a positive relationship between the difficulty of the task and LPP.

## Valence and difficulty ratings

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(valence, difficulty)) +
  geom_jitter(height = 0.2, width = 0.2) + 
  ggtitle("Valence and difficulty ratings")
```

There doesn't appear to be a relationship between the two, but we can test this.

```{r, message=FALSE, warning=FALSE}
mod_diff_val <- lmerTest::lmer(difficulty ~ valence + (1|pid), data = per_erp_int)

summary(mod_diff_val)

library(lme4)
```

I stand corrected. There is a relationship. Let's check the effect size:

```{r}
effectsize::standardize_parameters(mod_diff_val) %>% pander()
```

## Valence and arousal

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(valence, arousal)) +
  geom_jitter(width = 0.3, height = 0.3) + 
  geom_smooth(method = "lm") +
  stat_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red") +
  ggtitle("Valence and arousal ratings")
```

It looks like there is a strong curvilinear relationship between the two. 

```{r, message=FALSE, warning=FALSE}
mod_val_arousal <- lmerTest::lmer(arousal ~ poly(valence, 2) + (1|pid), data = per_erp_int)

summary(mod_val_arousal)
```

The MLM analysis confirms this relationship.

## Arousal and difficulty ratings

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(arousal, difficulty)) +
  geom_jitter(height = 0.3, width = 0.3) + 
  ggtitle("Arousal and difficulty ratings")
```

There is perhaps a curvilinear relationship. Let's model a locally weighted (green) and polynomial regression (red) line on the plot to see what the relationship is, and how well the polynomial regression line fits compared to the locally weighted one.

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(arousal, difficulty)) +
  geom_jitter(height = 0.3, width = 0.3) + 
  geom_smooth(color = "green", alpha = 0.2) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.2) +
  ggtitle("Arousal and difficulty ratings")
```

It looks like the curvilnear relationship may be a good fit. Let's test it with an MLM analysis

```{r, warning=FALSE, message=FALSE}
mod_diff_arousal <- lmerTest::lmer(difficulty ~ poly(arousal, 2) + (1|pid), data = per_erp_int)

summary(mod_diff_arousal)
```

Indeed, the results indicated that the relationship is curvilinear.