---
title: "Exploratory Data Analyses for PER Project"
author: "Ian Kahrilas"
date: "2/10/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(here)
library(pander)
library(ggpubr)
library(car)
library(robustlmm)
library(emmeans)
library(easystats)
library(moments)
library(modelbased)
library(patchwork)
library(report)
library(r2glmm)
# load in data
erp_mast_wide <- read_csv(here("data", "created_data", "erp_mast.csv"))
erp_avr_wide <- read_csv(here("data", "created_data", "erp_avr.csv"))
per_questionnaires <- read_csv(here("data", "created_data", "per_measures.csv"))
```

```{r averaging and questionnaire variable selection, include = FALSE}
lpp_elec_right <- c("B23", "B24", "B26", "B27")
lpp_elec_left <- c("A27", "A26", "A30", "A29")
epn_elec_right <- c("B25", "B26", "B24")
epn_elec_left <- c("A28", "A27", "A29")
# select variabes from questionnaire data set for analyses
measures_int <- per_questionnaires %>% 
  select(pid:valence, sex, Race, political_orientation, coffee_typical_day:typical_sleep_hours,
         anticipating:masq_aa, tmms_repair, depression)

LPP_right <- erp_mast_wide %>%
  select(all_of(lpp_elec_right), pid:prop_trials) %>% 
  filter(between(ms, 400, 1000)) %>%
  pivot_longer(., cols = all_of(lpp_elec_right), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(LPP_right = mean(mv, na.rm = TRUE),
            prop_trials = mean(prop_trials, na.rm = TRUE))

LPP_left <- erp_mast_wide %>%
  select(all_of(lpp_elec_left), pid:prop_trials) %>% 
  filter(between(ms, 400, 1000)) %>%
  pivot_longer(., cols = all_of(lpp_elec_left), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(LPP_left = mean(mv, na.rm = TRUE))

EPN_right <- erp_avr_wide %>%
  select(all_of(epn_elec_right), pid:prop_trials) %>% 
  filter(between(ms, 240, 375)) %>%
  pivot_longer(., cols = all_of(epn_elec_right), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(EPN_right = mean(mv, na.rm = TRUE))

EPN_left <- erp_avr_wide %>%
  select(all_of(epn_elec_left), pid:prop_trials) %>% 
  filter(between(ms, 240, 375)) %>%
  pivot_longer(., cols = all_of(epn_elec_left), names_to = "electrode", values_to = "mv") %>% 
  group_by(pid, block) %>% 
  summarize(EPN_left = mean(mv, na.rm = TRUE))
```

Join all the tibbles together
```{r join all tibbles together, include=FALSE}
#join all LPP tibbles plus right frontal
per_erp <- left_join(LPP_left, LPP_right, by = c("pid", "block")) %>%
  left_join(EPN_left, by = c("pid", "block")) %>%
  left_join(EPN_right, by = c("pid", "block")) %>%
  left_join(measures_int, by = c("pid", "block"))
```

Change variable classes for parsimonious exploration and analysis

```{r change variable classes}
# pid as character type
per_erp$pid <- as.character(per_erp$pid)
# block as factor
per_erp$block <- as.factor(per_erp$block)
per_erp <- per_erp %>% 
  select(pid, block, prop_trials, everything())
```
## Questionnaire Descriptive Statisitcs

```{r descriptive stats on variables of interest}
per_erp %>% 
  ungroup() %>% 
  summarize("PA Mean" = mean(pos_affectivity, na.rm = TRUE),
            "PA SD" = sd(pos_affectivity, na.rm = TRUE),
            "NA Mean" = mean(neg_affectivity, na.rm = TRUE),
            "NA SD" = sd(neg_affectivity, na.rm = TRUE),
            "StM Mean" = mean(savoring_moment, na.rm = TRUE),
            "StM SD" = sd(savoring_moment, na.rm = TRUE)) %>% 
  pander(split.tables = 200, caption = "PA = Positive Affectivity, NA = Negative Affectivity, StM = Savoring the Moment")
```

## EEG Descriptive Statistics by Block

```{r descriptive statistics for LPP}
per_erp %>% 
  group_by(block) %>% 
  summarize("LPP Right Mean" = mean(LPP_right, na.rm = TRUE),
            "LPP Right SD" = sd(LPP_right, na.rm = TRUE),
            "LPP Left Mean" = mean(LPP_left, na.rm = TRUE),
            "LPP Left SD" = sd(LPP_left, na.rm = TRUE),
            "EPN Right Mean" = mean(EPN_right, na.rm = TRUE),
            "EPN Right SD" = sd(EPN_right, na.rm = TRUE),
            "EPN Left Mean" = mean(EPN_left, na.rm = TRUE),
            "EPN Left SD" = sd(EPN_left, na.rm = TRUE),
            "Valence Mean" = mean(valence, na.rm = TRUE),
            "Valence SD" = sd(valence, na.rm = TRUE),
            "Arousal Mean" = mean(arousal, na.rm = TRUE),
            "Arousal SD" = sd(arousal, na.rm = TRUE), 
            "Difficulty Mean" = mean(difficulty, na.rm = TRUE),
            "Difficulty SD" = sd(difficulty, na.rm = TRUE))
```

# Normality Tests

## Positive Affectivity

```{r PA histogram}
per_erp %>% 
  group_by(pid) %>% 
  summarize(pos_affectivity = mean(pos_affectivity, na.rm = TRUE)) %>% 
  ggplot(., (aes(pos_affectivity))) +
    geom_histogram(bins = 15) +
    ggtitle("PA Histogram")
```

```{r PA QQplot}
per_erp %>% 
  group_by(pid) %>% 
  summarize(pos_affectivity = mean(pos_affectivity, na.rm = TRUE)) %>% 
  ggplot(., aes(sample = pos_affectivity)) + 
  stat_qq() +
  stat_qq_line() +
  ggtitle("PA QQPlot")
```

It would appear that there is a slight negative skew to the data, though it does not deviate from a gaussian distribution substantially. Let's confirm with a shapiro-wilk test for normality

```{r shapiro-wilk test for positive affectivity, echo = FALSE}
pid_pa <- per_erp %>% 
  group_by(pid) %>% 
  summarize(pos_affectivity = mean(pos_affectivity, na.rm = TRUE))
shapiro.test(pid_pa$pos_affectivity) %>% 
  pander()
```

It is not significant, suggesting that the distribution of PA does not significantly deviate from the normal distribution.

## Negative Affectivity

```{r negative affectivity histogram}
per_erp %>% 
  group_by(pid) %>% 
  summarize(neg_affectivity = mean(neg_affectivity, na.rm = TRUE)) %>% 
  ggplot(., (aes(neg_affectivity))) +
    geom_histogram(bins = 15) +
    ggtitle("NA Histogram")
```

```{r negative affectivity qqplot}
per_erp %>% 
  group_by(pid) %>% 
  summarize(neg_affectivity = mean(neg_affectivity, na.rm = TRUE)) %>% 
  ggplot(., aes(sample = neg_affectivity)) + 
  stat_qq() +
  stat_qq_line() +
  ggtitle("NA QQPlot")
```

```{r shapiro-wilk test for NA}
pid_na <- per_erp %>% 
  group_by(pid) %>% 
  summarize(neg_affectivity = mean(neg_affectivity, na.rm = TRUE))
shapiro.test(pid_na$neg_affectivity) %>% 
  pander()
```

NA does not significantly deviate from the normal distribution.

## Savoring the Moment

```{r StM histogram}
per_erp %>% 
  group_by(pid) %>% 
  summarize(savoring_moment = mean(savoring_moment, na.rm = TRUE)) %>% 
  ggplot(., (aes(savoring_moment))) +
    geom_histogram(bins = 14) +
    ggtitle("Savoring the Moment Histogram")
```

```{r StM qqplot}
per_erp %>% 
  group_by(pid) %>% 
  summarize(savoring_moment = mean(savoring_moment, na.rm = TRUE)) %>% 
  ggplot(., aes(sample = savoring_moment)) + 
  stat_qq() +
  stat_qq_line() +
  ggtitle("Savoring the Moment QQPlot")
```
```{r shapiro-wilk test for StM}
pid_StM <- per_erp %>% 
  group_by(pid) %>% 
  summarize(savoring_moment = mean(savoring_moment, na.rm = TRUE))
shapiro.test(pid_StM$savoring_moment) %>% 
  pander()
```

## LPP

### Histograms and QQplots for each block
```{r histograms and qqplots for LPP and EPN for each block, warning = FALSE, message = FALSE}
eeg_by_pid <- per_erp %>% 
  group_by(pid, block) %>% 
  summarize(LPP_right = mean(LPP_right, na.rm = TRUE),
            LPP_left = mean(LPP_left, na.rm = TRUE),
            EPN_right = mean(EPN_right, na.rm = TRUE),
            EPN_left = mean(EPN_left, na.rm = TRUE))

hist_qq_fun <- function(trial, component) {
(eeg_by_pid %>% 
  filter(block == trial) %>% 
  select(component) %>% 
  gghistogram(., x = component) |
eeg_by_pid %>% 
  filter(block == trial) %>% 
  select(component) %>% 
  ggqqplot(., component)) +
  plot_annotation(title = paste(trial, component))
}

blocks <- unique(as.character(eeg_by_pid$block))
components <- names(eeg_by_pid)[3:6]

map(components, ~map(blocks, ~hist_qq_fun(trial = .x, component = .y), .y = .x))
```

Inspect some of the extreme cases indicated in the histograms.

```{r examine extreme cases, warning=FALSE,message=FALSE}
# character string of outlier pids
outlier_pids <- unique(c(eeg_by_pid %>% 
                           filter(block == "Neg_Dec", LPP_right < -10) %>% 
                           select(pid) %>% 
                           pull(),
                         eeg_by_pid %>% 
                           filter(block == "Neu_Watch", LPP_right < -9, LPP_right > 10) %>% 
                           select(pid) %>% 
                           pull(),
                         eeg_by_pid %>% 
                           filter(block == "Pos_Inc", LPP_right < -9) %>% 
                           select(pid) %>% 
                           pull(),
                         eeg_by_pid %>% 
                           filter(block == "Neu_Watch", LPP_left > 10) %>% 
                           select(pid) %>% 
                           pull(),
                         eeg_by_pid %>% 
                           filter(block == "Neg_Dec", EPN_right < -20) %>% 
                           select(pid) %>% 
                           pull(),
                         eeg_by_pid %>% 
                           filter(block == "Pos_Dec", EPN_right < -20) %>% 
                           select(pid) %>% 
                           pull(),
                         eeg_by_pid %>% 
                           filter(block == "Pos_Inc", EPN_right < -20) %>% 
                           select(pid) %>% 
                           pull(),
                         eeg_by_pid %>% 
                           filter(block == "Neu_Watch", EPN_left > 15) %>% 
                           select(pid) %>% 
                           pull()))
                  
# inspect cases
eeg_by_pid %>% 
  filter(pid %in% outlier_pids)

# make duplicate data frame with extreme values replaced with NA
eeg_by_pid_filter <- eeg_by_pid

eeg_by_pid_filter$LPP_right[eeg_by_pid_filter$LPP_right > 10 | eeg_by_pid_filter$LPP_right < -9] <- NA
eeg_by_pid_filter$LPP_left[eeg_by_pid_filter$LPP_left > 12] <- NA
eeg_by_pid_filter$EPN_right[eeg_by_pid_filter$EPN_right < -20] <- NA
eeg_by_pid_filter$EPN_left[eeg_by_pid_filter$EPN_left > 15] <- NA
```

Our extreme cases are `outlier_pids`. Re-run histograms and QQ plots with the extreme datapoints omitted. 

```{r remove noisy participants, warning=FALSE, message=FALSE}
hist_qq_fun_filter <- function(trial, component) {
(eeg_by_pid_filter %>% 
  filter(block == trial) %>% 
  select(component) %>% 
  gghistogram(., x = component) |
eeg_by_pid_filter %>% 
  filter(block == trial) %>% 
  select(component) %>% 
  ggqqplot(., component)) +
  plot_annotation(title = paste(trial, component))
}

map(components, ~map(blocks, ~hist_qq_fun_filter(trial = .x, component = .y), .y = .x))
```

Create second dataset with outliers omitted. Create average LPP and EPN variables as well as variable indicating lateralization

```{r manipulate the dataset to facilitate bivariate analyses}
# construct a second data frame without the outlier datapoints
per_erp_filter <- per_erp
per_erp_filter$LPP_right[per_erp_filter$LPP_right > 10 | per_erp_filter$LPP_right < -9] <- NA
per_erp_filter$LPP_left[per_erp_filter$LPP_left > 12] <- NA
per_erp_filter$EPN_right[per_erp_filter$EPN_right < -20] <- NA
per_erp_filter$EPN_left[per_erp_filter$EPN_left > 15] <- NA
# average eeg components
per_erp <- per_erp %>% 
  mutate(LPP_avg = (LPP_right + LPP_left) / 2,
         EPN_avg = (EPN_right + EPN_left) / 2)
per_erp_filter <- per_erp_filter %>% 
  mutate(LPP_avg = (LPP_right + LPP_left) / 2,
         EPN_avg = (EPN_right + EPN_left) / 2)
# create side variable for lateralization in both data sets
tmp_LPP <- per_erp %>% 
  select(-contains("EPN_")) %>% 
  pivot_longer(c(LPP_right, LPP_left, LPP_avg), names_to = "lateralization", values_to = "LPP") %>% 
  mutate(lateralization = str_remove(lateralization, "LPP_")) %>% 
  mutate(lateralization = as.factor(lateralization))
tmp_EPN <- per_erp %>% 
  select(-contains("LPP_")) %>% 
  pivot_longer(c(EPN_right, EPN_left, EPN_avg), names_to = "lateralization", values_to = "EPN") %>% 
  mutate(lateralization = str_remove(lateralization, "EPN_")) %>% 
  mutate(lateralization = as.factor(lateralization)) %>% 
  select(pid, block, EPN, lateralization)
per_erp_lat <- full_join(tmp_LPP, tmp_EPN, by = (c("pid", "block", "lateralization"))) %>% 
  select(pid, block, prop_trials, LPP, EPN, lateralization, everything())
# filtered dataset
tmp_LPP_filter <- per_erp_filter %>% 
  select(-contains("EPN")) %>% 
  pivot_longer(c(LPP_right, LPP_left, LPP_avg), names_to = "lateralization", values_to = "LPP") %>% 
  mutate(lateralization = str_remove(lateralization, "LPP_")) %>% 
  mutate(lateralization = as.factor(lateralization))
tmp_EPN_filter <- per_erp_filter %>% 
  select(-contains("LPP")) %>% 
  pivot_longer(c(EPN_right, EPN_left, EPN_avg), names_to = "lateralization", values_to = "EPN") %>% 
  mutate(lateralization = str_remove(lateralization, "EPN_")) %>% 
  mutate(lateralization = as.factor(lateralization)) %>% 
  select(pid, block, EPN, lateralization)
per_erp_filter_lat <- full_join(tmp_LPP_filter, tmp_EPN_filter, by = (c("pid", "block", "lateralization"))) %>% 
  select(pid, block, prop_trials, LPP, EPN, lateralization, everything())
```

# Bivariate Relationships

## LPP, EPN, and block condition

```{r visualize LPP by block, warning=FALSE}
# box and whisker plots
per_erp_lat %>% 
  mutate(lateralization = fct_relevel(lateralization, c("left", "avg", "right"))) %>% 
  ggplot(., aes(block, LPP, color = lateralization)) +
  geom_boxplot() +
  ggtitle("LPP box and whisker plots for each block")
per_erp_filter_lat %>% 
  mutate(lateralization = fct_relevel(lateralization, c("left", "avg", "right"))) %>% 
  ggplot(., aes(block, LPP, color = lateralization)) +
  geom_boxplot() + 
  ggtitle("LPP box and whisker plots for each block\nwith filtered dataset")
per_erp_lat %>% 
  mutate(lateralization = fct_relevel(lateralization, c("left", "avg", "right"))) %>% 
  ggplot(., aes(block, EPN, color = lateralization)) +
  geom_boxplot() +
  ggtitle("EPN box and whisker plots for each block")
per_erp_filter_lat %>% 
  mutate(lateralization = fct_relevel(lateralization, c("left", "avg", "right"))) %>% 
  ggplot(., aes(block, EPN, color = lateralization)) +
  geom_boxplot() +
  ggtitle("EPN box and whisker plots for each block\nwith filtered dataset")
```

Based on these observations, the filtered dataset will be used for hypothesis testing.

## Contrasts between conditions

```{r contrasts, message = FALSE, warning = FALSE}
# unfiltered LPP
per_erp_lat$block <- relevel(per_erp_lat$block, "Neu_Watch")
block_mod_lpp <- lmerTest::lmer(LPP ~ block*lateralization + (1|lateralization:pid) + (lateralization|pid), data = per_erp_lat)
performance::check_model(block_mod_lpp, panel = FALSE)
summary(block_mod_lpp)
# contrasts
emmeans(block_mod_lpp, pairwise ~ lateralization | block)
emmip(block_mod, block ~ lateralization) # plot

# filtered LPP
block_mod_lpp_filter <- lmerTest::lmer(LPP ~ block*lateralization + (1|lateralization:pid) + (lateralization|pid), data = per_erp_filter_lat)
summary(block_mod_lpp_filter)
performance::check_model(block_mod_lpp_filter, panel = FALSE)
# contrasts
emmeans(block_mod_lpp_filter, pairwise ~ lateralization | block)
emmip(block_mod_filter, block ~ lateralization) # plot

# unfiltered EPN
block_mod_epn <- lmerTest::lmer(EPN ~ block*lateralization + (1|lateralization:pid) + (lateralization|pid), data = per_erp_lat)
summary(block_mod_epn)
performance::check_model(block_mod_epn, panel = FALSE)
# contrasts
emmeans(block_mod_epn, pairwise ~ lateralization | block)
emmip(block_mod_epn, block ~ lateralization) # plot

# filtered EPN
block_mod_epn_filter <- lmerTest::lmer(EPN ~ block*lateralization + (1|lateralization:pid) + (lateralization|pid), data = per_erp_filter_lat)
summary(block_mod_epn_filter)
performance::check_model(block_mod_epn_filter, panel = FALSE)
# contrasts
emmeans(block_mod_epn_filter, pairwise ~ lateralization | block)
emmip(block_mod_epn_filter, block ~ lateralization) # plot
```

## Aim One: Passive Blocks

```{r hypothesis one, message=FALSE}
# fit null model for LPP
null_lpp_model <- lmer(LPP ~ (1|pid), data = filter(per_erp_filter_lat, lateralization == "avg"))
# check intraclass correlation
performance::icc(null_lpp_model)
# 42.9% of the variance in LPP can be explained by between-participant effects.
# relevel block variable
per_erp_filter_lat$block <-  relevel(per_erp_filter_lat$block, "Neu_Watch")
# fit model one
mod_one <- lmerTest::lmer(LPP ~ block + (1|pid), data = filter(per_erp_filter_lat, lateralization == "avg"))
# check assumptions
check_model(mod_one)
summary(mod_one)
report(mod_one) # APA style reporting
r2beta(mod_one) # semi-partial R2
# fit model one, but with epn as outcome
# ICC
null_epn_model <- lmer(EPN ~ (1|pid), data = filter(per_erp_filter_lat, lateralization == "avg"))
icc(null_epn_model)
# 76.5% of the  variance in EPN can be explained by between-participant effects
# fit model one with EPN
mod_one_epn <- lmerTest::lmer(EPN ~ block + (1|pid), data = filter(per_erp_filter_lat, lateralization == "right"))
# check assumptions
check_model(mod_one_epn)
summary(mod_one_epn)
report(mod_one_epn)
r2beta(mod_one_epn)
# add in lateralization interaction term
mod_one_epn_lat <- lmerTest::lmer(EPN ~ block * lateralization + (1|lateralization:pid) + (lateralization|pid), data = per_erp_filter_lat)
summary(mod_one_epn_lat)
report(mod_one_epn_lat)
```

## Aim Two: LPP and Positive Affectivity

Derive contrasts between neutral watch and positive watch conditions and observe relationship between this contrast and positive affectivity, which is in line with the study hypothesis that the LPP contrast between the neutral watch and positive watch conditions will be moderated by positive affectivity

```{r pos affectivity contrasts}
mod_two_lpp <- lmerTest::lmer(LPP ~ block * scale(pos_affectivity, center = TRUE, scale = FALSE) + (1|pid), data = per_erp_filter_lat %>% filter(lateralization == "avg"))
# check assumptions
check_model(mod_two_lpp, panel = FALSE)
summary(mod_two_lpp)
plot(rlmer(LPP ~ block * scale(pos_affectivity, center = TRUE, scale = FALSE) + (1|pid), data = per_erp_filter_lat %>% filter(lateralization == "avg")))

pos_watch_contrast <- per_erp_int %>% 
  filter(block == "Neu_Watch") %>%
  rename("LPP_neu_watch" = LPP) %>% 
  select(-block)

tmp <- per_erp_int %>% 
  filter(block == "Pos_Watch") %>% 
  rename("LPP_pos_watch" = LPP) %>% 
  select(pid, LPP_pos_watch)

pos_watch_contrast <- full_join(pos_watch_contrast, tmp, by = "pid") %>% 
  mutate(contrast = LPP_pos_watch - LPP_neu_watch)

ggplot(pos_watch_contrast, aes(pos_affectivity, contrast)) +
  geom_point() +
  ggtitle("Positive affectivity and contrast between \nNeutral Watch and Positive Watch")
```

There doesn't appear to be any relationship between the two. We can derive a Pearson Product Moment correlation coefficient between contrasts and positive affectivity to validate this.

```{r}
cor.test(pos_watch_contrast$contrast, pos_watch_contrast$pos_affectivity) %>% pander()
```

## LPP and savoring the  moment

Derive contrasts between positive watch and positive increase conditions and observe relationship between this contrast and savoring the moment, which is in line with the study hypothesis that the LPP contrast between the positive watch and positive increase conditions will be moderated by savoring the moment.

```{r savoring moment contrasts}
pos_inc_contrast <- per_erp_int %>% 
  filter(block == "Pos_Watch") %>%
  rename("LPP_pos_watch" = LPP) %>% 
  select(-block)

tmp <- per_erp_int %>% 
  filter(block == "Pos_Inc") %>% 
  rename("LPP_pos_inc" = LPP) %>% 
  select(pid, LPP_pos_inc)

pos_inc_contrast <- full_join(pos_inc_contrast, tmp, by = "pid") %>% 
  mutate(contrast = LPP_pos_inc - LPP_pos_watch)

ggplot(pos_inc_contrast, aes(savoring_moment, contrast)) +
  geom_jitter() +
  ggtitle("Momentary savoring and contrast between \nPositive Watch and Positive Increase")
```

Again, there does not appear to be a relationship between the two variables. Let's derive Pearson Product Moment correlation coefficient between the contrast and savoring the moment to confirm.

```{r}
cor.test(pos_inc_contrast$contrast, pos_inc_contrast$savoring_moment) %>% pander()
```

## LPP and arousal ratings

Scatterplot between LPP and arousal ratings

```{r arousal ratings and LPP}
ggplot(per_erp_int, aes(arousal, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) +
  ggtitle("Arousal ratings and LPP")
```

There appears to be a positive linear relationship between the two. Let's test a linear model using MLM to account for the clustering between participants.

```{r}
mod_arousal <- lmerTest::lmer(LPP ~ arousal + (1|pid), data = per_erp_int)

summary(mod_arousal)
```

Results indicate a significant linear relationship between arousal and LPP.

## LPP and valence ratings

Scatterplot between LPP and valence ratings

```{r valence ratings and LPP, warning=FALSE, message=FALSE}
ggplot(per_erp_int, aes(valence, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) + 
  ggtitle("Valence ratings and LPP")
```

At first glance, there does not appear to be a relationship. However, it is hypothesized that more negatively- and positively-valenced images may positively correlate with LPP. Let's test this by fitting a polynomial regression line through the scatterplot.

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(valence, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) + 
  stat_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  ggtitle("Valence ratings and LPP")
```

Now, conduct a polynomial regression using MLM.

```{r}
mod_valence <- lmerTest::lmer(LPP ~ poly(valence, 2) + (1|pid), data = per_erp_int)

summary(mod_valence)
```

Results indicate that there is a curvilinear relationship between LPP and arousal.

## LPP and difficulty ratings

Scatterplot between LPP and dificulty ratings.

```{r difficulty ratings and LPP, warning=FALSE, message=FALSE}
ggplot(per_erp_int, aes(difficulty, LPP)) +
  geom_jitter(width = 0.1, height = 0.1) + 
  ggtitle("Difficulty ratings and LPP")
```

There may be a slight linear relationship, though it is weak. Let's try fitting a linear model to test this.

```{r, warning=FALSE, message=FALSE}
mod_difficulty <- lmerTest::lmer(LPP ~ difficulty + (1|pid), data = per_erp_int)

summary(mod_difficulty)
```

There does appear to be a positive relationship between the difficulty of the task and LPP.

## Valence and difficulty ratings

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(valence, difficulty)) +
  geom_jitter(height = 0.2, width = 0.2) + 
  ggtitle("Valence and difficulty ratings")
```

There doesn't appear to be a relationship between the two, but we can test this.

```{r, message=FALSE, warning=FALSE}
mod_diff_val <- lmerTest::lmer(difficulty ~ valence + (1|pid), data = per_erp_int)

summary(mod_diff_val)

library(lme4)
```

I stand corrected. There is a relationship. Let's check the effect size:

```{r}
effectsize::standardize_parameters(mod_diff_val) %>% pander()
```

## Valence and arousal

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(valence, arousal)) +
  geom_jitter(width = 0.3, height = 0.3) + 
  geom_smooth(method = "lm") +
  stat_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red") +
  ggtitle("Valence and arousal ratings")
```

It looks like there is a strong curvilinear relationship between the two. 

```{r, message=FALSE, warning=FALSE}
mod_val_arousal <- lmerTest::lmer(arousal ~ poly(valence, 2) + (1|pid), data = per_erp_int)

summary(mod_val_arousal)
```

The MLM analysis confirms this relationship.

## Arousal and difficulty ratings

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(arousal, difficulty)) +
  geom_jitter(height = 0.3, width = 0.3) + 
  ggtitle("Arousal and difficulty ratings")
```

There is perhaps a curvilinear relationship. Let's model a locally weighted (green) and polynomial regression (red) line on the plot to see what the relationship is, and how well the polynomial regression line fits compared to the locally weighted one.

```{r, message=FALSE, warning=FALSE}
ggplot(per_erp_int, aes(arousal, difficulty)) +
  geom_jitter(height = 0.3, width = 0.3) + 
  geom_smooth(color = "green", alpha = 0.2) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.2) +
  ggtitle("Arousal and difficulty ratings")
```

It looks like the curvilnear relationship may be a good fit. Let's test it with an MLM analysis

```{r, warning=FALSE, message=FALSE}
mod_diff_arousal <- lmerTest::lmer(difficulty ~ poly(arousal, 2) + (1|pid), data = per_erp_int)

summary(mod_diff_arousal)
```

Indeed, the results indicated that the relationship is curvilinear.